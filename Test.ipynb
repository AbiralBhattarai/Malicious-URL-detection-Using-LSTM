{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OX4vGz8A9VM3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import  nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Embedding,Dense, Activation\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot,Tokenizer\n",
        "from collections import Counter\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9u8dmns9XNo",
        "outputId": "425aa7c5-f9e4-4c8f-c209-ccbde0926318"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/balanced dataset.csv')\n",
        "inputs = df['url']\n",
        "labels = df['type']\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoUpnPsE9uQq",
        "outputId": "b083d20d-90b3-4ebb-c76c-b2432c77dba2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         0\n",
              "2         1\n",
              "3         1\n",
              "4         1\n",
              "         ..\n",
              "426051    1\n",
              "426052    1\n",
              "426053    0\n",
              "426054    0\n",
              "426055    0\n",
              "Name: type, Length: 426056, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=1000000,oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(inputs)\n",
        "word_index = tokenizer.word_index\n",
        "word_index['facebook']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcIZvCRL9whW",
        "outputId": "e86a9cdc-b58b-4cdc-e681-e0451ac188fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(inputs)\n",
        "len(word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgDiBWnU92Kd",
        "outputId": "d30739f9-30d8-444d-f533-6b94d2fea02c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "388968"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(sublist) for sublist in sequences]\n",
        "\n",
        "max_length = max(lengths)\n",
        "min_length=min(lengths)\n",
        "print(max_length)\n",
        "print(min_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm90idzR-HON",
        "outputId": "3cbc9bc6-3884-4f81-c51b-8fefbb18ca16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "244\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = pad_sequences(sequences,maxlen=244)\n",
        "features = features.astype(float)"
      ],
      "metadata": {
        "id": "Pl9D_Zvk-Ijp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_frac = 0.8\n",
        "split_idx = int(len(features)*split_frac)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = labels[:split_idx], labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.1)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "train_x=train_x[:-44]\n",
        "train_y=train_y[:-44]\n",
        "val_x=val_x[:-21]\n",
        "val_y=val_y[:-21]\n",
        "test_x=test_x[:-91]\n",
        "test_y=test_y[:-91]\n",
        "\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOrfLXND-KNK",
        "outputId": "5027d0f7-a261-4cb4-d934-1ad54728a1ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(340800, 244) \n",
            "Validation set: \t(8500, 244) \n",
            "Test set: \t\t(76600, 244)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(np.asarray(train_x)), torch.from_numpy(np.asarray(train_y)))\n",
        "valid_data = TensorDataset(torch.from_numpy(np.asarray(val_x)), torch.from_numpy(np.asarray(val_y)))\n",
        "test_data = TensorDataset(torch.from_numpy(np.asarray(test_x)), torch.from_numpy(np.asarray(test_y)))\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=100)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=100)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=100)"
      ],
      "metadata": {
        "id": "hag3mqRh-Lzv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Features,Labels=next(iter(train_loader))"
      ],
      "metadata": {
        "id": "9Z0Ly7Zz-Opl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu=torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "7ZmM34Lg-RPx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class malicious(nn.Module):\n",
        "  def __init__(self,vocab_size,output_size,embedding_dim,hidden_dim,n_layers,drop_prob=0.5):\n",
        "    super(malicious,self).__init__()\n",
        "    self.output_size=output_size\n",
        "    self.n_layers=n_layers\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.embedding=nn.Embedding(vocab_size,embedding_dim)\n",
        "    self.lstm=nn.LSTM(embedding_dim,hidden_dim,n_layers,dropout=drop_prob,batch_first=True)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.fc=nn.Linear(hidden_dim,output_size)\n",
        "\n",
        "  def forward(self,x,hidden):\n",
        "    batch_size=x.size(0)\n",
        "    x=x.long()\n",
        "    embeds=self.embedding(x)\n",
        "    lstm_out,hidden=self.lstm(embeds,hidden)\n",
        "    lstm_out=lstm_out[:, -1, :] # getting the last time step output\n",
        "    output=self.dropout(lstm_out)\n",
        "    output=F.sigmoid(self.fc(output))\n",
        "    return output,hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "    return hidden"
      ],
      "metadata": {
        "id": "QB-rk6Wv-TiZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(word_index)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size=1\n",
        "embedding_dim=512\n",
        "hidden_dim=256\n",
        "n_layers=2\n",
        "\n",
        "model=malicious(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjIuhxJy-VcP",
        "outputId": "6f543166-39ad-434c-9463-ef6b775daf20"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "malicious(\n",
            "  (embedding): Embedding(388969, 512)\n",
            "  (lstm): LSTM(512, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.BCELoss()\n",
        "optimizer= Adam(model.parameters(),lr=0.001)\n",
        "batch_size= 100"
      ],
      "metadata": {
        "id": "6Kd71YEQ-Wxk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume = torch.load('/content/drive/MyDrive/controlled3.pth')"
      ],
      "metadata": {
        "id": "IVpyumur-Zg5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(resume['state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU08U3Dm-h1W",
        "outputId": "4d86d821-d577-427c-8b4a-c19e21362dfb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def add_spaces_around_punctuation(input_list):\n",
        "    translation_table = str.maketrans({key: f' {key} ' for key in string.punctuation})\n",
        "    result_list = [s.translate(translation_table) for s in input_list]\n",
        "    result_list = [s.split() for s in result_list]\n",
        "\n",
        "    return result_list\n",
        "\n",
        "def pad_features(reviews_ints, seq_length):\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "    return features\n",
        "\n",
        "def predict(feature_tensor):\n",
        "  with torch.no_grad():\n",
        "    model.cuda()\n",
        "    h = model.init_hidden(feature_tensor.size(0))\n",
        "    model.eval()\n",
        "    h = tuple([each.data for each in h])\n",
        "    if(train_on_gpu):\n",
        "      feature_tensor= feature_tensor.cuda()\n",
        "    output,h = model(feature_tensor,h)\n",
        "    pred = torch.round(output.squeeze())\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "    if(pred.item()==0):\n",
        "      print(\"Not Malicious\")\n",
        "    else:\n",
        "      print(\"Malicious\")\n",
        "\n",
        "url=[input(\"Enter Url: \")]\n",
        "output_list = add_spaces_around_punctuation(url)\n",
        "\n",
        "reviews_ints = []\n",
        "for review in output_list:\n",
        "    reviews_ints.append([word_index.get(word, 0) for word in review])\n",
        "\n",
        "seq_length = 326\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n",
        "assert len(features) == len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
        "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "feature_tensor=torch.from_numpy(features)\n",
        "predict(feature_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w1L50BT-lu0",
        "outputId": "7f125cbc-0cea-436d-e78a-5a1b9b5769d9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Url: linkedin.com/in/abiral-bhattarai-a76247256/\n",
            "Prediction value, pre-rounding: 0.412903\n",
            "Not Malicious\n"
          ]
        }
      ]
    }
  ]
}